{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d42aab-28e8-45ec-a275-60a632f0529a",
   "metadata": {},
   "source": [
    "## Notebook: Rule based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd02d6",
   "metadata": {},
   "source": [
    "This notebook explores some rule-based and syntactic techniques. We'll use these methods to uncover patterns in complexity, theory usage, and framing in the academic literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a0cdeb-74b2-4429-bebc-bf32d10f112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cad2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/merged_scopus.csv\")\n",
    "\n",
    "valid_types = ['Article', 'Book', 'Book chapter', 'Review']\n",
    "df = df[df['Document Type'].isin(valid_types)]\n",
    "\n",
    "df['text'] = df['Title'].fillna('') + '. ' + df['Abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1a3e",
   "metadata": {},
   "source": [
    "### Examine sentence complexity and readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5039.000000</td>\n",
       "      <td>5039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.000938</td>\n",
       "      <td>20.575191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.514406</td>\n",
       "      <td>4.504787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-44.856591</td>\n",
       "      <td>5.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.892368</td>\n",
       "      <td>17.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.793442</td>\n",
       "      <td>20.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.787231</td>\n",
       "      <td>23.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.816136</td>\n",
       "      <td>54.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       readability  avg_sent_len\n",
       "count  5039.000000   5039.000000\n",
       "mean     16.000938     20.575191\n",
       "std      12.514406      4.504787\n",
       "min     -44.856591      5.958904\n",
       "25%       7.892368     17.625000\n",
       "50%      16.793442     20.285714\n",
       "75%      24.787231     23.200000\n",
       "max      62.816136     54.125000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "df['readability'] = df['text'].apply(textstat.flesch_reading_ease)\n",
    "df['avg_sent_len'] = df['text'].apply(lambda x: sum(len(sent.split()) for sent in x.split('.') if sent.strip()) / max(1, x.count('.')))\n",
    "df[['readability', 'avg_sent_len']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e9a90-ad0b-4fa6-8c94-e445910ef9bf",
   "metadata": {},
   "source": [
    "### Complexity by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d9d4d4-2509-4e1b-aba5-b193ce2d0481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Journal of Medical Internet Research</th>\n",
       "      <td>22.941082</td>\n",
       "      <td>19.655134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Environmental Research and Public Health</th>\n",
       "      <td>21.510420</td>\n",
       "      <td>19.707787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expert Systems with Applications</th>\n",
       "      <td>18.532374</td>\n",
       "      <td>21.789061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frontiers in Public Health</th>\n",
       "      <td>18.180444</td>\n",
       "      <td>19.784370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Advanced Computer Science and Applications</th>\n",
       "      <td>16.879073</td>\n",
       "      <td>17.983764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLoS ONE</th>\n",
       "      <td>16.285762</td>\n",
       "      <td>21.101791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applied Sciences (Switzerland)</th>\n",
       "      <td>14.208316</td>\n",
       "      <td>20.366472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sustainability (Switzerland)</th>\n",
       "      <td>13.902759</td>\n",
       "      <td>21.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British Journal of Educational Technology</th>\n",
       "      <td>13.505625</td>\n",
       "      <td>21.911533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technological Forecasting and Social Change</th>\n",
       "      <td>13.103491</td>\n",
       "      <td>21.677279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heliyon</th>\n",
       "      <td>13.062838</td>\n",
       "      <td>21.025997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IEEE Access</th>\n",
       "      <td>11.737610</td>\n",
       "      <td>19.841040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Journal of Cleaner Production</th>\n",
       "      <td>11.684974</td>\n",
       "      <td>23.757210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientific Reports</th>\n",
       "      <td>10.542672</td>\n",
       "      <td>19.971001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humanities and Social Sciences Communications</th>\n",
       "      <td>9.794030</td>\n",
       "      <td>20.960639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    readability  avg_sent_len\n",
       "Source title                                                                 \n",
       "Journal of Medical Internet Research                  22.941082     19.655134\n",
       "International Journal of Environmental Research...    21.510420     19.707787\n",
       "Expert Systems with Applications                      18.532374     21.789061\n",
       "Frontiers in Public Health                            18.180444     19.784370\n",
       "International Journal of Advanced Computer Scie...    16.879073     17.983764\n",
       "PLoS ONE                                              16.285762     21.101791\n",
       "Applied Sciences (Switzerland)                        14.208316     20.366472\n",
       "Sustainability (Switzerland)                          13.902759     21.046160\n",
       "British Journal of Educational Technology             13.505625     21.911533\n",
       "Technological Forecasting and Social Change           13.103491     21.677279\n",
       "Heliyon                                               13.062838     21.025997\n",
       "IEEE Access                                           11.737610     19.841040\n",
       "Journal of Cleaner Production                         11.684974     23.757210\n",
       "Scientific Reports                                    10.542672     19.971001\n",
       "Humanities and Social Sciences Communications          9.794030     20.960639"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 15 most common journals in the dataset\n",
    "top_sources = df['Source title'].value_counts().head(15).index\n",
    "\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "\n",
    "readability_summary = df_top.groupby('Source title')[['readability', 'avg_sent_len']].mean()\n",
    "readability_summary = readability_summary.sort_values('readability', ascending=False)\n",
    "readability_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91bbef",
   "metadata": {},
   "source": [
    "### Detecting theories using dictionary matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f300b87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dictionary/theories.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the theory dictionary\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Each row in the CSV should look like: Theory, Term\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m theories_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDictionary/theories.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create a mapping of term → theory\u001b[39;00m\n\u001b[32m      8\u001b[39m theory_terms = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Dictionary/theories.csv'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Load the theory dictionary\n",
    "# Each row in the CSV should look like: Theory, Term\n",
    "theories_df = pd.read_csv('Dictionary/theories.csv')\n",
    "\n",
    "# Create a mapping of term → theory\n",
    "theory_terms = {}\n",
    "for _, row in theories_df.iterrows():\n",
    "    theory = row['Theory']\n",
    "    terms = row['Term'].split('; ')  # Assuming terms are separated by \"; \"\n",
    "    for term in terms:\n",
    "        theory_terms[term.lower()] = theory\n",
    "\n",
    "# Compile regex patterns with word boundaries for accurate matches\n",
    "compiled_patterns = {\n",
    "    re.compile(r'\\b{}\\b'.format(re.escape(term)), re.IGNORECASE): theory\n",
    "    for term, theory in theory_terms.items()\n",
    "}\n",
    "\n",
    "# Define a function to find which theories are mentioned\n",
    "def find_theories(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    matched = set()\n",
    "    for pattern, theory in compiled_patterns.items():\n",
    "        if pattern.search(text):\n",
    "            matched.add(theory)\n",
    "    return '; '.join(sorted(matched)) if matched else None\n",
    "\n",
    "# Apply it to the dataset\n",
    "df['Theory'] = df['text'].apply(find_theories)\n",
    "\n",
    "# Preview\n",
    "df[['text', 'Theory']].dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96467ae0-d2e7-411f-b6e6-c0d3ad44f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Theory  count\n",
      "0                    network theory     50\n",
      "1                  discourse theory     31\n",
      "2                 complexity theory     24\n",
      "3            policy feedback theory     13\n",
      "4                       game theory      8\n",
      "5   diffusion of innovations theory      8\n",
      "6        narrative policy framework      8\n",
      "7              institutional theory      7\n",
      "8        multiple streams framework      5\n",
      "9     punctuated equilibrium theory      4\n",
      "10                   systems theory      3\n",
      "11    social construction framework      3\n",
      "12     advocacy coalition framework      3\n",
      "13                  critical theory      1\n",
      "14                   framing theory      1\n",
      "15             public choice theory      1\n",
      "16            social capital theory      1\n",
      "17                  prospect theory      1\n",
      "18          ecology of games theory      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/wckl14yn6sd0ctxq6z8bchpn27jk_c/T/ipykernel_13641/2728697762.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  theory_count.column = ['Theory', 'Count']\n"
     ]
    }
   ],
   "source": [
    "theory_count = df['Theory'].str.split(';').explode().str.strip().value_counts().reset_index()\n",
    "\n",
    "# Renaming columns for better readability\n",
    "theory_count.column = ['Theory', 'Count']\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(theory_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb969d-a7c8-45ac-8a72-ac81b3a0ece4",
   "metadata": {},
   "source": [
    "### Detecting normative language (modal verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ba9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8071.000000\n",
       "mean        1.185355\n",
       "std         1.511243\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        19.000000\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can be implemented as a rule-based approach, but here we demonstrate its use with a pre-trained model\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def count_modals(text):\n",
    "    doc = nlp(text)\n",
    "    return sum(1 for token in doc if token.tag_ == 'MD')\n",
    "\n",
    "df['modal_count'] = df['text'].apply(count_modals)\n",
    "df['modal_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a582548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source title\n",
       "Journal of Medical Internet Research                                 2.047619\n",
       "Proceedings of Machine Learning Research                             1.354167\n",
       "Technological Forecasting and Social Change                          1.326531\n",
       "International Journal of Environmental Research and Public Health    1.282609\n",
       "Lecture Notes in Networks and Systems                                1.253968\n",
       "ACM International Conference Proceeding Series                       1.226891\n",
       "CEUR Workshop Proceedings                                            1.219512\n",
       "PLoS ONE                                                             1.207317\n",
       "Advances in Neural Information Processing Systems                    1.192982\n",
       "IEEE Access                                                          1.093750\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normativity by journal (top 10 by average modal count)\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "df_top.groupby('Source title')['modal_count'].mean().sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
