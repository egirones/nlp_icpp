{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d42aab-28e8-45ec-a275-60a632f0529a",
   "metadata": {},
   "source": [
    "## Notebook: Rule based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd02d6",
   "metadata": {},
   "source": [
    "This notebook explores some rule-based and syntactic techniques. We'll use these methods to uncover patterns in complexity, theory usage, and framing in the academic literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a0cdeb-74b2-4429-bebc-bf32d10f112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cad2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/merged_scopus.csv\")\n",
    "\n",
    "valid_types = ['Article', 'Book', 'Book chapter', 'Review']\n",
    "df = df[df['Document Type'].isin(valid_types)]\n",
    "\n",
    "df['text'] = df['Title'].fillna('') + '. ' + df['Abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1a3e",
   "metadata": {},
   "source": [
    "### Examine sentence complexity and readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5039.000000</td>\n",
       "      <td>5039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.000938</td>\n",
       "      <td>20.575191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.514406</td>\n",
       "      <td>4.504787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-44.856591</td>\n",
       "      <td>5.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.892368</td>\n",
       "      <td>17.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.793442</td>\n",
       "      <td>20.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.787231</td>\n",
       "      <td>23.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.816136</td>\n",
       "      <td>54.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       readability  avg_sent_len\n",
       "count  5039.000000   5039.000000\n",
       "mean     16.000938     20.575191\n",
       "std      12.514406      4.504787\n",
       "min     -44.856591      5.958904\n",
       "25%       7.892368     17.625000\n",
       "50%      16.793442     20.285714\n",
       "75%      24.787231     23.200000\n",
       "max      62.816136     54.125000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "df['readability'] = df['text'].apply(textstat.flesch_reading_ease)\n",
    "df['avg_sent_len'] = df['text'].apply(lambda x: sum(len(sent.split()) for sent in x.split('.') if sent.strip()) / max(1, x.count('.')))\n",
    "df[['readability', 'avg_sent_len']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e9a90-ad0b-4fa6-8c94-e445910ef9bf",
   "metadata": {},
   "source": [
    "### Complexity by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d9d4d4-2509-4e1b-aba5-b193ce2d0481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Journal of Medical Internet Research</th>\n",
       "      <td>22.941082</td>\n",
       "      <td>19.655134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Environmental Research and Public Health</th>\n",
       "      <td>21.510420</td>\n",
       "      <td>19.707787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expert Systems with Applications</th>\n",
       "      <td>18.532374</td>\n",
       "      <td>21.789061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frontiers in Public Health</th>\n",
       "      <td>18.180444</td>\n",
       "      <td>19.784370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Advanced Computer Science and Applications</th>\n",
       "      <td>16.879073</td>\n",
       "      <td>17.983764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLoS ONE</th>\n",
       "      <td>16.285762</td>\n",
       "      <td>21.101791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applied Sciences (Switzerland)</th>\n",
       "      <td>14.208316</td>\n",
       "      <td>20.366472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sustainability (Switzerland)</th>\n",
       "      <td>13.902759</td>\n",
       "      <td>21.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British Journal of Educational Technology</th>\n",
       "      <td>13.505625</td>\n",
       "      <td>21.911533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technological Forecasting and Social Change</th>\n",
       "      <td>13.103491</td>\n",
       "      <td>21.677279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heliyon</th>\n",
       "      <td>13.062838</td>\n",
       "      <td>21.025997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IEEE Access</th>\n",
       "      <td>11.737610</td>\n",
       "      <td>19.841040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Journal of Cleaner Production</th>\n",
       "      <td>11.684974</td>\n",
       "      <td>23.757210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientific Reports</th>\n",
       "      <td>10.542672</td>\n",
       "      <td>19.971001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humanities and Social Sciences Communications</th>\n",
       "      <td>9.794030</td>\n",
       "      <td>20.960639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    readability  avg_sent_len\n",
       "Source title                                                                 \n",
       "Journal of Medical Internet Research                  22.941082     19.655134\n",
       "International Journal of Environmental Research...    21.510420     19.707787\n",
       "Expert Systems with Applications                      18.532374     21.789061\n",
       "Frontiers in Public Health                            18.180444     19.784370\n",
       "International Journal of Advanced Computer Scie...    16.879073     17.983764\n",
       "PLoS ONE                                              16.285762     21.101791\n",
       "Applied Sciences (Switzerland)                        14.208316     20.366472\n",
       "Sustainability (Switzerland)                          13.902759     21.046160\n",
       "British Journal of Educational Technology             13.505625     21.911533\n",
       "Technological Forecasting and Social Change           13.103491     21.677279\n",
       "Heliyon                                               13.062838     21.025997\n",
       "IEEE Access                                           11.737610     19.841040\n",
       "Journal of Cleaner Production                         11.684974     23.757210\n",
       "Scientific Reports                                    10.542672     19.971001\n",
       "Humanities and Social Sciences Communications          9.794030     20.960639"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 15 most common journals in the dataset\n",
    "top_sources = df['Source title'].value_counts().head(15).index\n",
    "\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "\n",
    "readability_summary = df_top.groupby('Source title')[['readability', 'avg_sent_len']].mean()\n",
    "readability_summary = readability_summary.sort_values('readability', ascending=False)\n",
    "readability_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91bbef",
   "metadata": {},
   "source": [
    "### Detecting theories using dictionary matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f300b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Load the theory dictionary\n",
    "# Each row in the CSV should look like: Theory, Term\n",
    "theories_df = pd.read_csv('Dictionary/theories.csv')\n",
    "\n",
    "# Create a mapping of term â†’ theory\n",
    "theory_terms = {}\n",
    "for _, row in theories_df.iterrows():\n",
    "    theory = row['Theory']\n",
    "    terms = row['Term'].split('; ')  # Assuming terms are separated by \"; \"\n",
    "    for term in terms:\n",
    "        theory_terms[term.lower()] = theory\n",
    "\n",
    "# Compile regex patterns with word boundaries for accurate matches\n",
    "compiled_patterns = {\n",
    "    re.compile(r'\\b{}\\b'.format(re.escape(term)), re.IGNORECASE): theory\n",
    "    for term, theory in theory_terms.items()\n",
    "}\n",
    "\n",
    "# Define a function to find which theories are mentioned\n",
    "def find_theories(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    matched = set()\n",
    "    for pattern, theory in compiled_patterns.items():\n",
    "        if pattern.search(text):\n",
    "            matched.add(theory)\n",
    "    return '; '.join(sorted(matched)) if matched else None\n",
    "\n",
    "# Apply it to the dataset\n",
    "df['Theory'] = df['text'].apply(find_theories)\n",
    "\n",
    "# Preview\n",
    "df[['text', 'Theory']].dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96467ae0-d2e7-411f-b6e6-c0d3ad44f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Theory  count\n",
      "0                    network theory     50\n",
      "1                  discourse theory     31\n",
      "2                 complexity theory     24\n",
      "3            policy feedback theory     13\n",
      "4                       game theory      8\n",
      "5   diffusion of innovations theory      8\n",
      "6        narrative policy framework      8\n",
      "7              institutional theory      7\n",
      "8        multiple streams framework      5\n",
      "9     punctuated equilibrium theory      4\n",
      "10                   systems theory      3\n",
      "11    social construction framework      3\n",
      "12     advocacy coalition framework      3\n",
      "13                  critical theory      1\n",
      "14                   framing theory      1\n",
      "15             public choice theory      1\n",
      "16            social capital theory      1\n",
      "17                  prospect theory      1\n",
      "18          ecology of games theory      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/wckl14yn6sd0ctxq6z8bchpn27jk_c/T/ipykernel_13641/2728697762.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  theory_count.column = ['Theory', 'Count']\n"
     ]
    }
   ],
   "source": [
    "theory_count = df['Theory'].str.split(';').explode().str.strip().value_counts().reset_index()\n",
    "\n",
    "# Renaming columns for better readability\n",
    "theory_count.column = ['Theory', 'Count']\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(theory_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb969d-a7c8-45ac-8a72-ac81b3a0ece4",
   "metadata": {},
   "source": [
    "### Detecting normative language (modal verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ba9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8071.000000\n",
       "mean        1.185355\n",
       "std         1.511243\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        19.000000\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can be implemented as a rule-based approach, but here we demonstrate its use with a pre-trained model\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def count_modals(text):\n",
    "    doc = nlp(text)\n",
    "    return sum(1 for token in doc if token.tag_ == 'MD')\n",
    "\n",
    "df['modal_count'] = df['text'].apply(count_modals)\n",
    "df['modal_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a582548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source title\n",
       "Journal of Medical Internet Research                                 2.047619\n",
       "Proceedings of Machine Learning Research                             1.354167\n",
       "Technological Forecasting and Social Change                          1.326531\n",
       "International Journal of Environmental Research and Public Health    1.282609\n",
       "Lecture Notes in Networks and Systems                                1.253968\n",
       "ACM International Conference Proceeding Series                       1.226891\n",
       "CEUR Workshop Proceedings                                            1.219512\n",
       "PLoS ONE                                                             1.207317\n",
       "Advances in Neural Information Processing Systems                    1.192982\n",
       "IEEE Access                                                          1.093750\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normativity by journal (top 10 by average modal count)\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "df_top.groupby('Source title')['modal_count'].mean().sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
