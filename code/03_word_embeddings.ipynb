{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48cf5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from gensim.downloader import load as gensim_load\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_manhattan_distances\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606a3b1",
   "metadata": {},
   "source": [
    "# 1. Let's use embeddings to map in a 3 dimensional space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a standard model.\n",
    "# load it and 'load' it into mps\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2aa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"monarchy\", \"republic\", \"kingdom\", \"monarch\", \"president\", \"prime minister\", \"senator\", \"theocracy\", \"democracy\", \"prince\"]\n",
    "colors = [\"red\", \"red\", \"red\", \"blue\", \"blue\", \"blue\", \"blue\", \"red\", \"red\", \"blue\"]\n",
    "embeddings = model.encode(words)\n",
    "reducer = umap.UMAP(n_components=3, random_state=42)\n",
    "embeddings_3d = reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=embeddings_3d[:, 0],\n",
    "    y=embeddings_3d[:, 1],\n",
    "    z=embeddings_3d[:, 2],\n",
    "    mode='markers+text',\n",
    "    text=words,\n",
    "    textposition='top center',\n",
    "    marker=dict(size=len(words), color=colors),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(range=[np.min(embeddings_3d[:, 0],)-0.5, np.max(embeddings_3d[:, 0],)+0.5]),  \n",
    "        yaxis=dict(range=[np.min(embeddings_3d[:, 1],)-0.5, np.max(embeddings_3d[:, 1],)+0.5]),  \n",
    "        zaxis=dict(range=[np.min(embeddings_3d[:, 2],)-0.5, np.max(embeddings_3d[:, 2],)+0.5]),\n",
    "        xaxis_title='UMAP 1 (X)',\n",
    "        yaxis_title='UMAP 2 (Y)',\n",
    "        zaxis_title='UMAP 3 (Z)'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d342e",
   "metadata": {},
   "source": [
    "# 2. Basic embeddings operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a507d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check this sentences\n",
    "\n",
    "# three sentences with similar meaning\n",
    "sent_a = \"The minister submitted a policy draft\"\n",
    "sent_b = \"The pub served warm draft beer\"\n",
    "sent_c = \"The NBA draft is taking place.\"\n",
    "sent_d = \"The bill has passed.\"\n",
    "\n",
    "sentences = [sent_a, sent_b, sent_c, sent_d]\n",
    "labels = [\"Parliamentary draft\", \"Beer\", \"NBA\", \"Parliamentary draft 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95e429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"mps\")\n",
    "embedding_a_768 = model.encode(sentences[0]) \n",
    "embedding_b_768 = model.encode(sentences[1]) \n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"mps\")\n",
    "embedding_a_384 = model.encode(sentences[0]) \n",
    "embedding_b_384 = model.encode(sentences[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ca7ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), (384,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_a_768.shape, embedding_a_384.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ab1c7",
   "metadata": {},
   "source": [
    "### How to measure similarity? Cosine similarity!\n",
    "\n",
    "Why? It measures direction and not length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdbc357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3df71e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"I like public policy\"\n",
    "sentence_b = \"I really like public policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f490da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_a = model.encode(sentence_a, convert_to_tensor=True)\n",
    "embedding_b = model.encode(sentence_b, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c28c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9627445936203003\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = util.cos_sim(embedding_a, embedding_b).item()\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cc1f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27296668\n"
     ]
    }
   ],
   "source": [
    "euclidean_dist = np.linalg.norm(embedding_a.cpu().numpy() - embedding_b.cpu().numpy())\n",
    "print(euclidean_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d9582",
   "metadata": {},
   "source": [
    "# 2. Static vs dynamics embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static embedding helper\n",
    "def static_embed(sentence, glove):\n",
    "    words = sentence.lower().split()\n",
    "    vectors = [glove[w] for w in words if w in glove]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "# similarity function\n",
    "def sim(v1, v2):\n",
    "    return round(cosine_similarity([v1], [v2])[0][0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use a function to help us do everything in one go\n",
    "\n",
    "def compare_embeddings(vectors, labels=labels):\n",
    "    vector = vectors[0]\n",
    "    label = labels[0]\n",
    "    for i, _ in enumerate(vectors):\n",
    "        v = vectors[i]\n",
    "        l = labels[i]        \n",
    "        print(sim(vector, v), \":\", label, \"vs\", l, )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model (it may take a few minutes)\n",
    "glove = gensim_load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3527a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STATIC EMBEDDINGS (GloVe)\")\n",
    "vectors = [static_embed(s, glove) for s in sentences]\n",
    "_ = compare_embeddings(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONTEXTUAL EMBEDDINGS\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"mps\")\n",
    "vectors = model.encode(sentences)\n",
    "_ = compare_embeddings(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16765412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONTEXTUAL EMBEDDINGS\")\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"mps\")\n",
    "vectors = model.encode(sentences)\n",
    "_ = compare_embeddings(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b5de7",
   "metadata": {},
   "source": [
    "Note! Each embedding model has different dimensions!\n",
    "\n",
    "More embeddings? More information can be captured by the vector! However, adding more vectors make comparison more difficult!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93820ddf",
   "metadata": {},
   "source": [
    "# 3. Dimensionality reduction\n",
    "\n",
    "Go back to slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd7565",
   "metadata": {},
   "source": [
    "Note! What happens when we add more information to the sentences?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
