{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d42aab-28e8-45ec-a275-60a632f0529a",
   "metadata": {},
   "source": [
    "## Notebook: Rule based analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd02d6",
   "metadata": {},
   "source": [
    "This notebook explores some rule-based and syntactic techniques. We'll use these methods to uncover patterns in complexity, theory usage, and framing in the academic literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a0cdeb-74b2-4429-bebc-bf32d10f112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cad2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/merged_scopus.csv\")\n",
    "\n",
    "valid_types = ['Article', 'Book', 'Book chapter', 'Review']\n",
    "df = df[df['Document Type'].isin(valid_types)]\n",
    "\n",
    "df['text'] = df['Title'].fillna('') + '. ' + df['Abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac1a3e",
   "metadata": {},
   "source": [
    "### Examine sentence complexity and readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5039.000000</td>\n",
       "      <td>5039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.000938</td>\n",
       "      <td>20.575191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.514406</td>\n",
       "      <td>4.504787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-44.856591</td>\n",
       "      <td>5.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.892368</td>\n",
       "      <td>17.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.793442</td>\n",
       "      <td>20.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.787231</td>\n",
       "      <td>23.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.816136</td>\n",
       "      <td>54.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       readability  avg_sent_len\n",
       "count  5039.000000   5039.000000\n",
       "mean     16.000938     20.575191\n",
       "std      12.514406      4.504787\n",
       "min     -44.856591      5.958904\n",
       "25%       7.892368     17.625000\n",
       "50%      16.793442     20.285714\n",
       "75%      24.787231     23.200000\n",
       "max      62.816136     54.125000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "df['readability'] = df['text'].apply(textstat.flesch_reading_ease)\n",
    "df['avg_sent_len'] = df['text'].apply(lambda x: sum(len(sent.split()) for sent in x.split('.') if sent.strip()) / max(1, x.count('.')))\n",
    "df[['readability', 'avg_sent_len']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e9a90-ad0b-4fa6-8c94-e445910ef9bf",
   "metadata": {},
   "source": [
    "### Complexity by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d9d4d4-2509-4e1b-aba5-b193ce2d0481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readability</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Journal of Medical Internet Research</th>\n",
       "      <td>22.941082</td>\n",
       "      <td>19.655134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Environmental Research and Public Health</th>\n",
       "      <td>21.510420</td>\n",
       "      <td>19.707787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expert Systems with Applications</th>\n",
       "      <td>18.532374</td>\n",
       "      <td>21.789061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frontiers in Public Health</th>\n",
       "      <td>18.180444</td>\n",
       "      <td>19.784370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Journal of Advanced Computer Science and Applications</th>\n",
       "      <td>16.879073</td>\n",
       "      <td>17.983764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLoS ONE</th>\n",
       "      <td>16.285762</td>\n",
       "      <td>21.101791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applied Sciences (Switzerland)</th>\n",
       "      <td>14.208316</td>\n",
       "      <td>20.366472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sustainability (Switzerland)</th>\n",
       "      <td>13.902759</td>\n",
       "      <td>21.046160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British Journal of Educational Technology</th>\n",
       "      <td>13.505625</td>\n",
       "      <td>21.911533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technological Forecasting and Social Change</th>\n",
       "      <td>13.103491</td>\n",
       "      <td>21.677279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heliyon</th>\n",
       "      <td>13.062838</td>\n",
       "      <td>21.025997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IEEE Access</th>\n",
       "      <td>11.737610</td>\n",
       "      <td>19.841040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Journal of Cleaner Production</th>\n",
       "      <td>11.684974</td>\n",
       "      <td>23.757210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scientific Reports</th>\n",
       "      <td>10.542672</td>\n",
       "      <td>19.971001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humanities and Social Sciences Communications</th>\n",
       "      <td>9.794030</td>\n",
       "      <td>20.960639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    readability  avg_sent_len\n",
       "Source title                                                                 \n",
       "Journal of Medical Internet Research                  22.941082     19.655134\n",
       "International Journal of Environmental Research...    21.510420     19.707787\n",
       "Expert Systems with Applications                      18.532374     21.789061\n",
       "Frontiers in Public Health                            18.180444     19.784370\n",
       "International Journal of Advanced Computer Scie...    16.879073     17.983764\n",
       "PLoS ONE                                              16.285762     21.101791\n",
       "Applied Sciences (Switzerland)                        14.208316     20.366472\n",
       "Sustainability (Switzerland)                          13.902759     21.046160\n",
       "British Journal of Educational Technology             13.505625     21.911533\n",
       "Technological Forecasting and Social Change           13.103491     21.677279\n",
       "Heliyon                                               13.062838     21.025997\n",
       "IEEE Access                                           11.737610     19.841040\n",
       "Journal of Cleaner Production                         11.684974     23.757210\n",
       "Scientific Reports                                    10.542672     19.971001\n",
       "Humanities and Social Sciences Communications          9.794030     20.960639"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 15 most common journals in the dataset\n",
    "top_sources = df['Source title'].value_counts().head(15).index\n",
    "\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "\n",
    "readability_summary = df_top.groupby('Source title')[['readability', 'avg_sent_len']].mean()\n",
    "readability_summary = readability_summary.sort_values('readability', ascending=False)\n",
    "readability_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91bbef",
   "metadata": {},
   "source": [
    "### Detecting theories using dictionary matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f300b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>The impact of LLM chatbots on learning outcome...</td>\n",
       "      <td>complexity theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Research on the Impact of the Synergy Between ...</td>\n",
       "      <td>policy feedback theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Central bank mandates and monetary policy stan...</td>\n",
       "      <td>discourse theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Proposed design of an augmented deep learning ...</td>\n",
       "      <td>complexity theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Image captioning with residual swin transforme...</td>\n",
       "      <td>network theory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                  Theory\n",
       "148  The impact of LLM chatbots on learning outcome...       complexity theory\n",
       "314  Research on the Impact of the Synergy Between ...  policy feedback theory\n",
       "338  Central bank mandates and monetary policy stan...        discourse theory\n",
       "363  Proposed design of an augmented deep learning ...       complexity theory\n",
       "374  Image captioning with residual swin transforme...          network theory"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Load the theory dictionary\n",
    "# Each row in the CSV should look like: Theory, Term\n",
    "theories_df = pd.read_csv('../data/theories.csv')\n",
    "\n",
    "# Create a mapping of term → theory\n",
    "theory_terms = {}\n",
    "for _, row in theories_df.iterrows():\n",
    "    theory = row['Theory']\n",
    "    terms = row['Term'].split('; ')  # Assuming terms are separated by \"; \"\n",
    "    for term in terms:\n",
    "        theory_terms[term.lower()] = theory\n",
    "\n",
    "# Compile regex patterns with word boundaries for accurate matches\n",
    "compiled_patterns = {\n",
    "    re.compile(r'\\b{}\\b'.format(re.escape(term)), re.IGNORECASE): theory\n",
    "    for term, theory in theory_terms.items()\n",
    "}\n",
    "\n",
    "# Define a function to find which theories are mentioned\n",
    "def find_theories(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    matched = set()\n",
    "    for pattern, theory in compiled_patterns.items():\n",
    "        if pattern.search(text):\n",
    "            matched.add(theory)\n",
    "    return '; '.join(sorted(matched)) if matched else None\n",
    "\n",
    "# Apply it to the dataset\n",
    "df['Theory'] = df['text'].apply(find_theories)\n",
    "\n",
    "# Preview\n",
    "df[['text', 'Theory']].dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96467ae0-d2e7-411f-b6e6-c0d3ad44f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Theory  count\n",
      "0                  discourse theory     27\n",
      "1                    network theory     27\n",
      "2                 complexity theory     16\n",
      "3            policy feedback theory      9\n",
      "4              institutional theory      7\n",
      "5   diffusion of innovations theory      6\n",
      "6        narrative policy framework      5\n",
      "7                       game theory      5\n",
      "8        multiple streams framework      4\n",
      "9     punctuated equilibrium theory      4\n",
      "10                   systems theory      3\n",
      "11    social construction framework      3\n",
      "12                   framing theory      1\n",
      "13                  critical theory      1\n",
      "14             public choice theory      1\n",
      "15     advocacy coalition framework      1\n",
      "16            social capital theory      1\n",
      "17                  prospect theory      1\n",
      "18          ecology of games theory      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/91/7hyydn8s7vld0bq80jm4m_l144y3vs/T/ipykernel_3857/2728697762.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  theory_count.column = ['Theory', 'Count']\n"
     ]
    }
   ],
   "source": [
    "theory_count = df['Theory'].str.split(';').explode().str.strip().value_counts().reset_index()\n",
    "\n",
    "# Renaming columns for better readability\n",
    "theory_count.column = ['Theory', 'Count']\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(theory_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb969d-a7c8-45ac-8a72-ac81b3a0ece4",
   "metadata": {},
   "source": [
    "### Detecting normative language (modal verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659ba9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esalasgirones/Documents/work/courses/nlp_icpp/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5039.000000\n",
       "mean        1.265330\n",
       "std         1.562528\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        19.000000\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can be implemented as a rule-based approach, but here we demonstrate its use with a pre-trained model\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def count_modals(text):\n",
    "    doc = nlp(text)\n",
    "    return sum(1 for token in doc if token.tag_ == 'MD')\n",
    "\n",
    "df['modal_count'] = df['text'].apply(count_modals)\n",
    "df['modal_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a582548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source title\n",
       "British Journal of Educational Technology                              3.918919\n",
       "Journal of Medical Internet Research                                   2.048077\n",
       "Expert Systems with Applications                                       1.521739\n",
       "Technological Forecasting and Social Change                            1.326531\n",
       "Applied Sciences (Switzerland)                                         1.303030\n",
       "International Journal of Environmental Research and Public Health      1.282609\n",
       "Heliyon                                                                1.240000\n",
       "PLoS ONE                                                               1.225000\n",
       "Frontiers in Public Health                                             1.142857\n",
       "International Journal of Advanced Computer Science and Applications    1.125000\n",
       "Name: modal_count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normativity by journal (top 10 by average modal count)\n",
    "df_top = df[df['Source title'].isin(top_sources)]\n",
    "df_top.groupby('Source title')['modal_count'].mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827cdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
